{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08895554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pathlib\n",
    "import torch\n",
    "import esm\n",
    "from esm import pretrained\n",
    "from esm import FastaBatchedDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92bf5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(output_dir, fasta_file, tokens_per_batch=4096, seq_length=7096, repr_layers=[36]):\n",
    "    model, alphabet = pretrained.esm2_t36_3B_UR50D()\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "    batches = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        collate_fn=alphabet.get_batch_converter(seq_length), \n",
    "        batch_sampler=batches\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filenames = []  \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in tqdm(enumerate(data_loader), total=len(batches)):\n",
    "            print(f'Processing batch {batch_idx + 1} of {len(batches)}')\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                toks = toks.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "\n",
    "            logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            representations = {layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()}\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                entry_id = label.split()[0]\n",
    "                filename = output_dir / f\"{entry_id}.pt\"\n",
    "                filenames.append(filename)  \n",
    "                truncate_len = min(seq_length, len(strs[i]))\n",
    "\n",
    "                result = {\"entry_id\": entry_id}\n",
    "                result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "\n",
    "                torch.save(result, filename)\n",
    "    return filenames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59cd1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('Channel_Proteins_Pred2-main/embeddings/example2.pt'),\n",
       " WindowsPath('Channel_Proteins_Pred2-main/embeddings/example1.pt')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy paste query sequence to query_sequence.txt file \n",
    "fasta_file = pathlib.Path('Channel_Proteins_Pred2-main/Input_sequences/Input_sequences.txt')\n",
    "output_dir = pathlib.Path('Channel_Proteins_Pred2-main/embeddings/')\n",
    "\n",
    "# Run the function\n",
    "extract_embeddings(output_dir, fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b1eb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "channel protein\n",
      "Non-channel protein\n"
     ]
    }
   ],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Load the query sequence representations\n",
    "def load_protein_representations(folder_path, files):\n",
    "    queryproteinrep = []\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            rep_changes = torch.load(file_path)['mean_representations'][36]\n",
    "            queryproteinrep.append(rep_changes.tolist())\n",
    "        else:\n",
    "            print(f\"File {file_path} not found.\")\n",
    "    return torch.tensor(queryproteinrep)\n",
    "\n",
    "# path to sequence representations\n",
    "folder_path = 'Channel_Proteins_Pred2-main/embeddings/'\n",
    "files_test = sorted(os.listdir(folder_path)) \n",
    "\n",
    "query_rep = load_protein_representations(folder_path, files_test)\n",
    "query_rep = query_rep.numpy()\n",
    "\n",
    "# neural network model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(2560,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1, activation='sigmoid') \n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    # Compile the model with the optimizer\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# Load the model \n",
    "best_weights_path = 'Channel_Proteins_Pred2-main/model/model.h5' \n",
    "model.load_weights(best_weights_path)\n",
    "\n",
    "# Using the model to make predictions\n",
    "predictions = model.predict(query_rep)\n",
    "predicted_labels = (predictions > 0.5).astype(int)\n",
    "\n",
    "for label in predicted_labels:\n",
    "    if label == 0:\n",
    "        print(\"Non-channel protein\")\n",
    "    if label == 1:\n",
    "        print(\"channel protein\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
